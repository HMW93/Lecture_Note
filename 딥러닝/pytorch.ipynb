{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM9L5LZAOSqu"
      },
      "source": [
        "파이토치는 2017년 초에 공개된 딥러닝 프레임워크로 개발자들과 연구자들이 쉽게 GPU를 활용하여 인공 신경망 모델을 만들고 학습시킬 수 있게 도와준다. 파이토치의 전신이라고 할 수 있는 토치(torch)는 루아 프로그래밍 언어로 되어 있었지만, 파이토치는 파이썬으로 작성되어 파이썬의 언어 특징을 많이 가지고 있다. \n",
        "\n",
        "파이토치는 페이스북의 인공지능 연구팀 멤버들이 주로 관리하며, 독자적으로 운영되는 파이토치 포럼은 사람들이 질문을 올리면 프레임워크 개발자를 비롯한 많은 사람이 답을 해주는 등 활발히 교류가 일어나고 있다.\n",
        "\n",
        "\n",
        "<img src = 'https://i.morioh.com/210325/12530f27.webp'>\n",
        "\n",
        "### PYTORCH가 무엇인가요?\n",
        "\n",
        "Python 기반의 과학 연산 패키지로 다음과 같은 두 집단을 대상으로 합니다:\n",
        "\n",
        "- NumPy를 대체하면서 GPU를 이용한 연산이 필요한 경우\n",
        "\n",
        "- 최대한의 유연성과 속도를 제공하는 딥러닝 연구 플랫폼이 필요한 경우\n",
        "\n",
        "PyTorch의 장점> (출처 : \"위키백과 : PyTorch\", 2019년 06월 19일)\n",
        "\n",
        "​\n",
        "\n",
        "● 설치의 간편하다\n",
        "\n",
        "● 이해와 디버깅이 쉬운 직관적이고 간결한 코드로 구성되었다\n",
        "\n",
        "● Define by Run 방식을 기반으로 한 실시간 결과값을 시각화한다\n",
        "\n",
        "● 파이썬 라이브러리(Numpy, Scipy, Cython)와 높은 호환성을 가진다\n",
        "\n",
        "● Winograd Convolution Alogithm 기본 적용을 통한 빠른 모델 훈련이 가능하다.\n",
        "\n",
        "● 모델 그래프를 만들 때 고정상태가 아니기 때문에 언제든지 데이터에 따라 조절이 가능하다(유연성)\n",
        "\n",
        "● Numpy스러운 Tensor연산이 GPU로도 가능하다\n",
        "\n",
        "● 자동 미분 시스템을 이용해 쉽게 DDN(DataDirect Networks을 짤 수 있다.\n",
        "\n",
        "● 학습 및 추론 속도가 빠르고 다루기 쉽다.\n",
        "\n",
        "​\n",
        "\n",
        "그러나 파이토치는 그래프 형태가 동적이기 때문에 계산 그래프를 매번 새롭게 정의하여 이용한다. 그래서  딥러닝 프레임워크 중 난이도가 높은편이다. 또한 사용자가 아직 적고 관련문서 또한 텐서플로우 등에 비해서 많은 편이 아니기 때문에 검색으로 공부하기 힘든 환경에 높여있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdtHykj9QVK-"
      },
      "source": [
        "## 텐서 : 데이터를 표현하는 단위"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5FRXtJoNFhd"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "#torch version :1.9 + cuda 10.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewH-1SPzQd8N"
      },
      "source": [
        "#스칼라 : 상수\n",
        "scalar1 = torch.tensor([1.])\n",
        "# print(scaler1)\n",
        "scalar2 = torch.tensor([3.])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcVhpLwtQtC9"
      },
      "source": [
        "add_scaler = scaler1+scalar2\n",
        "print(add_scaler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tmWbTnBQ2gP"
      },
      "source": [
        "sub_scalar = scalar1 - scalar2\n",
        "print(sub_scalar)\n",
        "#곱셈, 나눗셈도 됨"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lQM7vFkRqG9"
      },
      "source": [
        "## Vector : 하나의 값을 표현할 때 2개 이상의 수치를 표현한 것.\n",
        "(한 점 이 있고 방향성이 vector(수학적인 정의)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoUf7y14RB2f"
      },
      "source": [
        "vector1 = torch.tensor([1. , 2. ,3.])\n",
        "vector2 = torch.tensor([4. , 5. ,6.])\n",
        "\n",
        "#사칙연산이 됨. torch.mul / vector1 *vector2\n",
        "# + :add / - : sub / * : multiple  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIGN496KSFYq"
      },
      "source": [
        "print(vector1*vector2)\n",
        "print(torch.mul(vector1,vector2))\n",
        "print(torch.dot(vector1,vector2)) #inner preodct."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiGPaxBDTKGG"
      },
      "source": [
        "matrix multiple / inner preduct은 다름\n",
        "\n",
        "numpy 특성 때문에 numpy.mul / numpy.dot 의 차이?\n",
        "\n",
        "numpy.dot -> 1차원 배열만 허락 ->numpy.mul->2차원 이상일때 작동->matrix mulitple->matrix.mult이 dot을 포함.\n",
        "\n",
        "numpy.dot->2차원이상을 하려고 하면 자동으로 numpy.mult로 바뀐다고 하였음. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBxAt4gBS_aE"
      },
      "source": [
        "# 행렬\n",
        "matrix1 = torch.tensor([[1. ,2.],\n",
        "                      [3., 4.]])\n",
        "\n",
        "matrix2 = torch.tensor([[5. ,6.],\n",
        "                      [7., 8.]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWOSCrPZUImX"
      },
      "source": [
        "print(torch.add(matrix1,matrix2))\n",
        "print(torch.sub(matrix1,matrix2))\n",
        "print(torch.mul(matrix1,matrix2))\n",
        "print(torch.div(matrix1,matrix2))\n",
        "print(torch.matmul(matrix1,matrix2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB2ZPxtjVhuc"
      },
      "source": [
        "## autograd()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsEUtOemU2Jj"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  DEVICE = torch.device('cuda')\n",
        "else:\n",
        "  DEVICE = torch.device('cpu')\n",
        "print(DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qODJ8qcxVwgB"
      },
      "source": [
        "batch_size = 64\n",
        "input_size = 1000\n",
        "hidden_size = 100\n",
        "output_size = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbi35opxWi9Z"
      },
      "source": [
        "x = torch.randn(batch_size,\n",
        "                input_size,\n",
        "                device = DEVICE,\n",
        "                dtype = torch.float,\n",
        "                requires_grad = False #gradinet를 하면서 gradient를 update하지 말아라.\n",
        "                )\n",
        "y = torch.randn(batch_size,\n",
        "                output_size,\n",
        "                device = DEVICE,\n",
        "                dtype = torch.float,\n",
        "                requires_grad = False #gradinet를 하면서 gradient를 update하지 말아라.\n",
        "                )\n",
        "w1 = torch.randn(input_size,\n",
        "                hidden_size,\n",
        "                device = DEVICE,\n",
        "                dtype = torch.float,\n",
        "                requires_grad = True \n",
        "                )\n",
        "w2 = torch.randn(hidden_size,\n",
        "                output_size,\n",
        "                device = DEVICE,\n",
        "                dtype = torch.float,\n",
        "                requires_grad = True \n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLB6bDBVZLWr"
      },
      "source": [
        "<img src = 'https://www.programmersought.com/images/352/8a7a0bc5350356e74947b6590af15b18.png'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbreUbR2YSDr"
      },
      "source": [
        "learning_rate = 1e-6\n",
        "for t in range(1,501):\n",
        "\n",
        "  y_pred = x.mm(w1).clamp(min =0).mm(w2) #mm : matrix multiple / clamp : relu와 비슷한 함수.\n",
        "\n",
        "  loss = (y_pred - y).pow(2).sum()\n",
        "  if t % 100 == 0: #100번마다 출력->print문\n",
        "    print('iteration :',t,'\\t','Loss:',loss.item())\n",
        "  loss.backward() #back propagation.->autograd\n",
        " \n",
        "  with torch.no_grad(): #gradient 더이상 update가 일어나지 않으면. 밑에다가 저장.\n",
        "    w1 -= learning_rate *w1.grad\n",
        "    w2 -= learning_rate *w2.grad\n",
        "\n",
        "    w1.grad.zero_() #w1의 gradient초기화 해주세요.\n",
        "    w2.grad.zero_() #w2의 gradient초기화 해주세요.\n",
        "\n",
        "    #초기화->loss.backward()->backprogation을 수행"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5vXCiMzZy1J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}